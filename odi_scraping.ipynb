{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a67c67",
   "metadata": {},
   "source": [
    "## ODI CRICKET SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da042db7",
   "metadata": {},
   "source": [
    "In this Project I scraped the match vise scorecard for last 5 years (2018 to 2023). \n",
    "The objective of the project was to analyze the the game as well as as based on data recommend best playing 11 for each of the Qualifying Nation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a6d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from alive_progress import alive_bar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "35b6fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website = \"https://www.espncricinfo.com/records/season/team-match-results/2014to15-2014to15?trophy=12\"\n",
    "# result = requests.get(website)\n",
    "# content = result.text\n",
    "# soup = BeautifulSoup(content, \"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12b3c7",
   "metadata": {},
   "source": [
    "#### I scraped the data from Cricinfo, wikipedia as well as other sites.\n",
    "### steps followed are as following:\n",
    "\n",
    "1. for each year (2018 - 2023) I scraped all the matched played in that year across all teams,\n",
    "check the function scrape_match_dataset. \n",
    "(which also contained links to the team profile as well as links for the Match detailed scorecard)\n",
    "\n",
    "2. for each year I went to each match link and scraped both the batting scorecard and bowling scorecard.\n",
    "(Data scraped in such a way that minimum effort is required in data modelling)\n",
    "(check the fucntions - scrape_batting_summary, srape_bowling_summary)\n",
    "\n",
    "3. After this from Match scorecard i also scraped the player links which helped me scrape cruiucla details about each player such as their stats, \n",
    "their nationality their preference order etc.\n",
    "\n",
    "4. Scraped National falgs for each team\n",
    "\n",
    "5. Because of issue of Lazy loading of player's images had to scrape the pictures using Selenium where I intialized delay time as 20 secounds and it will keep on increasing the time by 5 seconds till 60 seconds, if image is still not loading. \n",
    "(code in second notebook along with data modelling and analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eae7c8",
   "metadata": {},
   "source": [
    "### Match_datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027f6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_match_dataset(website):\n",
    "    \n",
    "    website = website\n",
    "    result = requests.get(website)\n",
    "    content = result.text\n",
    "    soup = BeautifulSoup(content, \"html\")\n",
    "    table = soup.find('table',class_=\"ds-w-full\")\n",
    "    \n",
    "    for row in table.thead.find_all(\"tr\"):\n",
    "        columns = row.find_all(\"td\")\n",
    "    column_headers = []\n",
    "    for i in columns:\n",
    "        column_headers.append(i.text.strip())\n",
    "    df_match= pd.DataFrame(columns=column_headers)\n",
    "    df_match=df_match.rename(columns={\"Match Date\":\"Match_Date\",\"Team 1\": \"Team_1\",\"Team 2\":\"Team_2\",\"Scorecard\":\"Match_id\"})\n",
    "    df_match\n",
    "\n",
    "\n",
    "    for row in table.tbody.find_all(\"tr\"):\n",
    "        columns = row.find_all(\"td\")\n",
    "\n",
    "        if(columns != []):\n",
    "            #Team_1_link = columns[0].span.a.get(\"href\")\n",
    "            Team_1 = columns[0].span.a.span.contents[0].strip()\n",
    "            Team_2 = columns[1].span.a.span.contents[0].strip()\n",
    "            Winner = columns[2].span.contents[0].strip()\n",
    "            Margin = columns[3].span.contents[0].strip()\n",
    "            Ground = columns[4].span.a.span.contents[0].strip()\n",
    "            Match_Date = columns[5].span.contents[0].strip()\n",
    "            Scorecard = columns[6].span.a.span.contents[0].strip()\n",
    "            #print(Scorecard)\n",
    "        df_match = df_match.append({\"Team_1\":Team_1,\n",
    "                                            \"Team_2\":Team_2,\n",
    "                                            \"Winner\":Winner,\n",
    "                                            \"Margin\":Margin,\n",
    "                                            \"Ground\":Ground,\n",
    "                                            \"Match_Date\":Match_Date,\n",
    "                                            \"Match_id\":Scorecard},\n",
    "                                           ignore_index=True)\n",
    "        \n",
    "    return df_match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6b92ed",
   "metadata": {},
   "source": [
    "### Match_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c550e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_match_links(website):\n",
    "    website = website\n",
    "    result = requests.get(website)\n",
    "    content = result.text\n",
    "    soup = BeautifulSoup(content, \"html\")\n",
    "    table = soup.find('table',class_=\"ds-w-full\")\n",
    "    df_match_links=pd.DataFrame(['Team_1_Link',\"Team_2_link\",\"Ground_link\",\"match_link\"])\n",
    "    for row in table.tbody.find_all(\"tr\"):\n",
    "        columns = row.find_all(\"td\")\n",
    "\n",
    "        if(columns != []):\n",
    "            Team_1_link = columns[0].span.a.get(\"href\")\n",
    "            Team_2_link = columns[1].span.a.get(\"href\")\n",
    "            Ground_link = columns[4].span.a.get(\"href\")\n",
    "            Scorecard_link = columns[6].span.a.get(\"href\")\n",
    "\n",
    "        df_match_links = df_match_links.append({\"Team_1_link\":Team_1_link,\n",
    "                                                        \"Team_2_link\":Team_2_link,\n",
    "                                                        \"Ground_link\":Ground_link,\n",
    "                                                        \"match_link\":Scorecard_link},\n",
    "                                                       ignore_index=True)\n",
    "    df_match_links=df_match_links.drop(columns=0)\n",
    "    df_match_links = df_match_links.dropna()\n",
    "    df_match_links=df_match_links.reset_index(drop=\"True\")\n",
    "    #df_match_links\n",
    "    return df_match_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30defb1d",
   "metadata": {},
   "source": [
    "### Batting Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5689934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_batting_summary(df_match_links,df_match):\n",
    "    #df match_battingstats()\n",
    "    df_match_links=df_match_links\n",
    "    \n",
    "    \n",
    "    df_batting_summary = pd.DataFrame(columns=[\"BATTING\",\"R\",\"B\",\"4s\",\"6s\",\"SR\",\"team\",\"Match_id\"])\n",
    "    df_batting_summary\n",
    "\n",
    "    for ind in df_match_links.index:\n",
    "            url =\"https://www.espncricinfo.com/\"+df_match_links[\"match_link\"][ind]\n",
    "            result = requests.get(url)\n",
    "            content = result.text\n",
    "            soup = BeautifulSoup(content, \"html\")\n",
    "\n",
    "            tables = soup.find_all(\"table\")\n",
    "\n",
    "            bat=0\n",
    "            for table in tables:\n",
    "                th_elements = table.find_all('th')\n",
    "                for th in th_elements:\n",
    "                    if \"BATTING\" in th.text:\n",
    "                        bat+=1\n",
    "\n",
    "            if bat==2:\n",
    "                table = tables[0]\n",
    "                for row in table.tbody.find_all(\"tr\"):\n",
    "                    columns = row.find_all(\"td\")\n",
    "                    #print(len(columns))\n",
    "                    if len(columns) == 8:\n",
    "                        #if(columns != []):\n",
    "                        Batsmen = columns[0].a.get(\"title\")\n",
    "                        Runs = columns[2].strong.contents[0]\n",
    "                        Balls = columns[3].contents[0].strip()\n",
    "                        No_4s = columns[5].contents[0].strip()\n",
    "                        No_6s = columns[6].contents[0].strip()\n",
    "                        Strike_rate = columns[7].contents[0].strip()\n",
    "                       #print(1)\n",
    "                        team = soup.find_all(\"span\",class_=\"ds-text-title-xs ds-font-bold ds-capitalize\")[0].contents[0]\n",
    "                        Match_id = df_match[\"Match_id\"][ind]\n",
    "                        df_bat1 =  pd.DataFrame([{\"BATTING\":Batsmen,\n",
    "                                                              \"R\":Runs,\n",
    "                                                              \"B\":Balls,\n",
    "                                                              \"4s\":No_4s,\n",
    "                                                              \"6s\":No_6s,\n",
    "                                                              \"SR\":Strike_rate,\n",
    "                                                              \"team\":team,\n",
    "                                                              \"Match_id\":Match_id}])\n",
    "                        df_batting_summary = pd.concat([df_batting_summary, df_bat1], ignore_index=True)\n",
    "\n",
    "                table = tables[2]\n",
    "                for row in table.tbody.find_all(\"tr\"):\n",
    "                    columns = row.find_all(\"td\")\n",
    "                    #print(len(columns))\n",
    "                    if len(columns) >= 8 :\n",
    "                        #if(columns != []):\n",
    "                        Batsmen = columns[0].a.get(\"title\")\n",
    "                        Runs = columns[2].strong.contents[0]\n",
    "                        Balls = columns[3].contents[0].strip()\n",
    "                        No_4s = columns[5].contents[0].strip()\n",
    "                        No_6s = columns[6].contents[0].strip()\n",
    "                        Strike_rate = columns[7].contents[0].strip()\n",
    "                        #print(1)\n",
    "                        team = soup.find_all(\"span\",class_=\"ds-text-title-xs ds-font-bold ds-capitalize\")[1].contents[0]\n",
    "                        Match_id = df_match[\"Match_id\"][ind]\n",
    "            #             df_batting_summary=df_batting_summary.append({\"BATTING\":Batsmen,\n",
    "            #                                                   \"R\":Runs,\n",
    "            #                                                   \"B\":Balls,\n",
    "            #                                                   \"4s\":No_4s,\n",
    "            #                                                   \"6s\":No_6s,\n",
    "            #                                                   \"SR\":Strike_rate,\n",
    "            #                                                   \"team\":team,\n",
    "            #                                                   \"Match_id\":Match_id},\n",
    "            #                                                  ignore_index=True)\n",
    "                        df_bat1 =  pd.DataFrame([{\"BATTING\":Batsmen,\n",
    "                                                              \"R\":Runs,\n",
    "                                                              \"B\":Balls,\n",
    "                                                              \"4s\":No_4s,\n",
    "                                                              \"6s\":No_6s,\n",
    "                                                              \"SR\":Strike_rate,\n",
    "                                                              \"team\":team,\n",
    "                                                              \"Match_id\":Match_id}])\n",
    "                        df_batting_summary = pd.concat([df_batting_summary, df_bat1], ignore_index=True)\n",
    "    return df_batting_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe291b",
   "metadata": {},
   "source": [
    "### Bowling_Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00f35e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_bowling_summary(df_match_links,df_match):\n",
    "    df_bowling_summary = pd.DataFrame(columns=[\"BOWLING\",\"O\",\"M\",\"R\",\"W\",\"ECON\",\"0s\",\"4s\",\"6s\",\"WD\",\"NB\",\"Match_id\",\"team\"])\n",
    "    df_bowling_summary\n",
    "    \n",
    "    df_match_links=df_match_links\n",
    "    for ind in df_match_links.index:\n",
    "        url =\"https://www.espncricinfo.com/\"+df_match_links[\"match_link\"][ind]\n",
    "        result = requests.get(url)\n",
    "        content = result.text\n",
    "        soup = BeautifulSoup(content, \"html\")\n",
    "\n",
    "        tables = soup.find_all(\"table\")\n",
    "        #if len(tables)>=4:\n",
    "        ball=0\n",
    "        for table in tables:\n",
    "            th_elements = table.find_all('th')\n",
    "            for th in th_elements:\n",
    "                if \"BOWLING\" in th.text:\n",
    "                    ball+=1\n",
    "\n",
    "        if ball==2:\n",
    "            table = tables[1]\n",
    "            for row in table.tbody.find_all(\"tr\",{\"class\":\"\"}):\n",
    "                columns = row.find_all(\"td\")\n",
    "                #print(len(columns[4]))\n",
    "                Bowlers = columns[0].a.span.contents[0].strip()\n",
    "                O = columns[1].contents[0].strip()\n",
    "                M = columns[2].contents[0].strip()\n",
    "                R = columns[3].contents[0].strip()\n",
    "                try:\n",
    "                    W = columns[4].span.strong.contents[0].strip()\n",
    "                except AttributeError:\n",
    "                    W = columns[4].strong.contents[0].strip()\n",
    "                ECON = columns[5].contents[0].strip()\n",
    "                No_0s = columns[6].contents[0].strip()\n",
    "                No_4s = columns[7].contents[0].strip()\n",
    "                No_6s = columns[8].contents[0].strip()\n",
    "                WD = columns[9].contents[0].strip()\n",
    "                NB = columns[10].contents[0].strip()\n",
    "    #             try:\n",
    "    #                 print(len(soup.find_all(\"span\",class_=\"ds-text-title-xs ds-font-bold ds-capitalize\")))\n",
    "                team = soup.find_all(\"span\",class_=\"ds-text-title-xs ds-font-bold ds-capitalize\")[1].contents[0]\n",
    "    #             except:\n",
    "    #                 import pdb\n",
    "    #                 pdb.set_trace()\n",
    "                #print(team)\n",
    "                Match_id = df_match[\"Match_id\"][ind]\n",
    "                #print(Bowlers,O,M,R,W,ECON,No_0s,No_4s,No_6s,WD,NB,team,Match_id)\n",
    "                df1 =  pd.DataFrame([{\"BOWLING\":Bowlers,\n",
    "                                \"O\":O,\n",
    "                                \"M\":M,\n",
    "                                \"R\":R,\n",
    "                                \"W\":W,\n",
    "                                \"ECON\":ECON,\n",
    "                                \"0s\":No_0s,\n",
    "                                \"4s\":No_4s,\n",
    "                                \"6s\":No_6s,\n",
    "                                \"WD\":WD,\n",
    "                                \"NB\":NB,\n",
    "                                \"Match_id\":Match_id,\n",
    "                                \"team\":team}])\n",
    "\n",
    "                df_bowling_summary = pd.concat([df_bowling_summary, df1], ignore_index=True)\n",
    "\n",
    "\n",
    "            table = tables[3]\n",
    "            for row in table.tbody.find_all(\"tr\",{\"class\":\"\"}):\n",
    "                columns = row.find_all(\"td\")\n",
    "                #print(len(columns[4]))\n",
    "                Bowlers = columns[0].a.span.contents[0].strip()\n",
    "                O = columns[1].contents[0].strip()\n",
    "                M = columns[2].contents[0].strip()\n",
    "                R = columns[3].contents[0].strip()\n",
    "                try:\n",
    "                    W = columns[4].span.strong.contents[0].strip()\n",
    "                except AttributeError:\n",
    "                    W = columns[4].strong.contents[0].strip()\n",
    "                ECON = columns[5].contents[0].strip()\n",
    "\n",
    "                No_0s = columns[6].contents[0].strip()\n",
    "\n",
    "                No_4s = columns[7].contents[0].strip()\n",
    "                No_6s = columns[8].contents[0].strip()\n",
    "                WD = columns[9].contents[0].strip()\n",
    "                NB = columns[10].contents[0].strip()\n",
    "                team = soup.find_all(\"span\",class_=\"ds-text-title-xs ds-font-bold ds-capitalize\")[0].contents[0]\n",
    "                Match_id = df_match[\"Match_id\"][ind]\n",
    "                #print(Bowlers,O,M,R,W,ECON,No_0s,No_4s,No_6s,WD,NB,team,Match_id)\n",
    "                #print(ECON, No_0s,NB)\n",
    "                df1 =  pd.DataFrame([{\"BOWLING\":Bowlers,\n",
    "                                \"O\":O,\n",
    "                                \"M\":M,\n",
    "                                \"R\":R,\n",
    "                                \"W\":W,\n",
    "                                \"ECON\":ECON,\n",
    "                                \"0s\":No_0s,\n",
    "                                \"4s\":No_4s,\n",
    "                                \"6s\":No_6s,\n",
    "                                \"WD\":WD,\n",
    "                                \"NB\":NB,\n",
    "                                \"Match_id\":Match_id,\n",
    "                                \"team\":team}])\n",
    "\n",
    "                df_bowling_summary = pd.concat([df_bowling_summary, df1], ignore_index=True)\n",
    "\n",
    "    #df_bowling_summary\n",
    "    return df_bowling_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04cae9",
   "metadata": {},
   "source": [
    "### Player_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ccd8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_links(df_match_links):\n",
    "    df_players = pd.DataFrame(columns=[\"Player_name\",\"Player_link\"])\n",
    "    \n",
    "    df_match_links=df_match_links\n",
    "    for ind in df_match_links.index:\n",
    "        url =\"https://www.espncricinfo.com/\"+df_match_links[\"match_link\"][ind]\n",
    "        result = requests.get(url)\n",
    "        content = result.text\n",
    "        soup = BeautifulSoup(content, \"html\")\n",
    "\n",
    "        tables = soup.find_all(\"table\")\n",
    "        ball=0\n",
    "        for table in tables:\n",
    "            th_elements = table.find_all('th')\n",
    "            for th in th_elements:\n",
    "                if \"BOWLING\" in th.text:\n",
    "                    ball+=1\n",
    "\n",
    "        bat=0\n",
    "        for table in tables:\n",
    "            th_elements = table.find_all('th')\n",
    "            for th in th_elements:\n",
    "                if \"BATTING\" in th.text:\n",
    "                    bat+=1\n",
    "\n",
    "        if bat==2 & ball==2:\n",
    "\n",
    "            table = tables[0]\n",
    "            for row in table.tbody.find_all(\"tr\"):\n",
    "                columns = row.find_all(\"td\")\n",
    "                #print(len(columns))\n",
    "                if len(columns) == 8:\n",
    "                    #if(columns != []):\n",
    "                    Batsmen = columns[0].a.get(\"title\")\n",
    "                    Batsmen_link = columns[0].a.get(\"href\")\n",
    "                    #print(1)\n",
    "                    df_players=df_players.append({\"Player_name\":Batsmen,\n",
    "                                                  \"Player_link\":Batsmen_link},\n",
    "                                                         ignore_index=True)\n",
    "            table = tables[2]\n",
    "            for row in table.tbody.find_all(\"tr\"):\n",
    "                columns = row.find_all(\"td\")\n",
    "                #print(len(columns))\n",
    "                if len(columns) == 8:\n",
    "                    #if(columns != []):\n",
    "                    Batsmen = columns[0].a.get(\"title\")\n",
    "                    Batsmen_link = columns[0].a.get(\"href\")\n",
    "                    #print(1)\n",
    "                    df_players=df_players.append({\"Player_name\":Batsmen,\n",
    "                                                  \"Player_link\":Batsmen_link},\n",
    "                                                         ignore_index=True)\n",
    "\n",
    "\n",
    "            table = tables[1]\n",
    "            for row in table.tbody.find_all(\"tr\",{\"class\":\"\"}):\n",
    "                columns = row.find_all(\"td\")\n",
    "                #print(len(columns[4]))\n",
    "                Bowlers = columns[0].a.span.contents[0].strip()\n",
    "                Bowlers_link = columns[0].a.get(\"href\")\n",
    "                df_players=df_players.append({\"Player_name\":Bowlers,\n",
    "                                                  \"Player_link\":Bowlers_link},\n",
    "                                                         ignore_index=True)\n",
    "\n",
    "            table = tables[3]\n",
    "            for row in table.tbody.find_all(\"tr\",{\"class\":\"\"}):\n",
    "                columns = row.find_all(\"td\")\n",
    "                #print(len(columns[4]))\n",
    "                Bowlers = columns[0].a.span.contents[0].strip()\n",
    "                Bowlers_link = columns[0].a.get(\"href\")\n",
    "                df_players=df_players.append({\"Player_name\":Bowlers,\n",
    "                                                  \"Player_link\":Bowlers_link},\n",
    "                                                         ignore_index=True)  \n",
    "    df_players = df_players.drop_duplicates()\n",
    "    df_players = df_players.reset_index(drop = True)\n",
    "    return df_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e856b",
   "metadata": {},
   "source": [
    "### Player_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af1e44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_details(df_players):\n",
    "    #with alive_bar(len(df_players),force_tty=True) as bar:\n",
    "    df_player_profile = pd.DataFrame(columns = [\"Name\",\"Born\",\"Age\",\"Batting_Style\",\"Bowling_Style\",\"Playing_Role\",\n",
    "                                             \"National_Team\",\"player_img\",\"career_start\",\"career_latest\"])\n",
    "    #df_player_profile\n",
    "    \n",
    "    df_players=df_players\n",
    "    for ind in df_players.index:\n",
    "        time.sleep(0.005)\n",
    "        url =\"https://www.espncricinfo.com/\"+df_players[\"Player_link\"][ind]\n",
    "        #print(url)\n",
    "        result = requests.get(url)\n",
    "        content = result.text\n",
    "        soup = BeautifulSoup(content, \"lxml\")\n",
    "\n",
    "\n",
    "        #Personal_details\n",
    "        list_names=[\"Full Name\",\"Born\",\"Age\",\"Batting Style\", \"Bowling Style\", \"Playing Role\"]\n",
    "        list_var_store = []\n",
    "        for i in range(len(list_names)):\n",
    "            box=soup.find(\"p\",text=list_names[i])\n",
    "            if box ==None:\n",
    "                list_var_store.append(\"\")\n",
    "            else:\n",
    "                list_var_store.append(box.parent.span.get_text())\n",
    "\n",
    "\n",
    "        Name = list_var_store[0]\n",
    "        Born = list_var_store[1]\n",
    "        Age = list_var_store[2]\n",
    "        Batting_Style = list_var_store[3]\n",
    "        Bowling_Style = list_var_store[4]\n",
    "        Playing_Role = list_var_store[5]\n",
    "        box = soup.find(\"p\",text=\"TEAMS\")\n",
    "        if box ==None:\n",
    "            National_Team = \"\"\n",
    "        else:\n",
    "            National_Team = box.parent.a.get_text()\n",
    "\n",
    "        #career span\n",
    "        elements = soup.find_all('span')\n",
    "        if elements==None:\n",
    "            career_span=\"\"\n",
    "        else:\n",
    "            for element in elements:\n",
    "                if 'INTL CAREER:' in element.text:\n",
    "                    career_span = element.text\n",
    "\n",
    "        pattern = r\"\\d{4}\"\n",
    "        years = re.findall(pattern, career_span)\n",
    "        career_start = years[0]\n",
    "        career_latest = years[1]\n",
    "\n",
    "        # Player_image\n",
    "        pattern = r\"/([^/]+)-\\d+$\"\n",
    "        matches = re.findall(pattern, url)\n",
    "        name_url = matches[0]\n",
    "        name_url = name_url.replace(\"-\",\" \").title().replace(\" \",\"_\")\n",
    "\n",
    "        url2=\"https://en.wikipedia.org/wiki/\"+name_url\n",
    "        result = requests.get(url2)\n",
    "        content = result.text\n",
    "        soup = BeautifulSoup(content, \"html\")\n",
    "        a = soup.find(\"span\",class_=\"mw-default-size\")\n",
    "        if a==None:\n",
    "            player_img=\"\"\n",
    "        else:\n",
    "            a = a.find(\"img\")\n",
    "            player_img=\"https:\"+a[\"src\"]\n",
    "\n",
    "\n",
    "        df1 =  pd.DataFrame([{\"Name\":Name,\n",
    "                              \"Born\":Born,\n",
    "                              \"Age\":Age,\n",
    "                              \"Batting_Style\":Batting_Style,\n",
    "                              \"Bowling_Style\":Bowling_Style,\n",
    "                              \"Playing_Role\":Playing_Role,\n",
    "                              \"National_Team\":National_Team,\n",
    "                              \"player_img\":player_img,\n",
    "                              \"career_start\":career_start,\n",
    "                              \"career_latest\":career_latest}])\n",
    "        #print(Name)\n",
    "        df_player_profile = pd.concat([df_player_profile, df1], ignore_index=True)\n",
    "        #print(ind)\n",
    "        #print(ind)\n",
    "        #bar()\n",
    "    return df_player_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97ff7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### National Teams & Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c5d1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_National_flag(df_match):\n",
    "    df_match=df_match\n",
    "    team1 = list(df_match['Team_1'].unique())\n",
    "    team2 = list(df_match['Team_2'].unique())\n",
    "    total_teams = list(set(team2+team1))\n",
    "\n",
    "\n",
    "\n",
    "    df_teams = pd.DataFrame(columns=[\"National_Team\",\"national_flag\"])\n",
    "\n",
    "    #National_flag\n",
    "    for i in total_teams:\n",
    "        #print(i)\n",
    "        National_Team = i.title()\n",
    "        National_Team=National_Team.replace(\" \",\"_\")\n",
    "        #print(National_Team)\n",
    "        url3=\"https://en.wikipedia.org/wiki/Flag_of_\"+National_Team\n",
    "        result = requests.get(url3)\n",
    "        content = result.text\n",
    "        soup = BeautifulSoup(content, \"html\")\n",
    "        a = soup.find_all(\"span\",class_=\"mw-image-border\")\n",
    "        #print(a)\n",
    "        if len(a)==0:\n",
    "            national_flag=\"\"\n",
    "        else:\n",
    "            national_flag = \"https:\"+a[0].find(\"img\")[\"src\"]\n",
    "        #print(national_flag)\n",
    "        df1 =  pd.DataFrame([{\"National_Team\":National_Team,\n",
    "                              \"national_flag\":national_flag}])\n",
    "        #print(Name)\n",
    "        #print(df1.columns)\n",
    "        df_teams = pd.concat([df_teams, df1], ignore_index=True) \n",
    "    \n",
    "    return df_teams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787d6a3",
   "metadata": {},
   "source": [
    "### Player_Batting_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5294d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_batting_stats(df_players):\n",
    "    with alive_bar(len(df_players),force_tty=True) as bar:\n",
    "\n",
    "        df_batting_stats = pd.DataFrame(columns = [\"Player_Name\",\"matches\",\"inns\",\"not_out\",\"runs_scored\",\"HS\",\n",
    "                                     \"batting_ave\",\"ball_faced\",\"batting_SR\",\"100s\",\"50s\",\"fours\",\"six\"])\n",
    "        df_players=df_players\n",
    "        for ind in df_players.index:\n",
    "            url =\"https://www.espncricinfo.com/\"+df_players[\"Player_link\"][ind]\n",
    "            #print(url)\n",
    "            result = requests.get(url)\n",
    "            content = result.text\n",
    "            soup = BeautifulSoup(content, \"lxml\")\n",
    "\n",
    "            Player_Name = df_players[\"Player_name\"][ind]\n",
    "            box2= soup.find(\"p\",text=\"Batting & Fielding\")\n",
    "            #for row in box2.parent.tbody.find_all(\"tr\")[:3]:\n",
    "            for row in box2.parent.tbody.find_all(\"tr\"):\n",
    "                columns = row.find_all(\"td\")\n",
    "                if columns[0].span.get_text()==\"ODI\":\n",
    "                    #print(columns[1].span.get_text())    \n",
    "\n",
    "\n",
    "                    columns = row.find_all(\"td\")\n",
    "                    matches = columns[1].span.get_text()\n",
    "                    inns = columns[2].span.get_text()\n",
    "                    not_out = columns[3].span.get_text()\n",
    "                    runs_scored = columns[4].span.get_text()\n",
    "                    HS = columns[5].span.get_text()\n",
    "                    batting_ave = columns[6].span.get_text()\n",
    "                    ball_faced = columns[7].span.get_text()\n",
    "                    batting_SR = columns[8].span.get_text()\n",
    "                    hundreds = columns[9].span.get_text()\n",
    "                    fiftys = columns[10].span.get_text()\n",
    "                    fours = columns[11].span.get_text()\n",
    "                    six = columns[12].span.get_text()\n",
    "\n",
    "            df1 =  pd.DataFrame([{\"Player_Name\":Player_Name,\n",
    "                        \"matches\":matches,\n",
    "                        \"inns\":inns,\n",
    "                        \"not_out\":not_out,\n",
    "                        \"runs_scored\":runs_scored,\n",
    "                        \"ball_faced\":ball_faced,\n",
    "                        \"HS\":HS,\n",
    "                        \"batting_ave\":batting_ave,\n",
    "                        \"batting_SR\":batting_SR,\n",
    "                        \"100s\":hundreds,\n",
    "                        \"50s\":fiftys,\n",
    "                        \"fours\":fours,\n",
    "                        \"six\":six}])\n",
    "                                  \n",
    "                #print(Name)\n",
    "            df_batting_stats = pd.concat([df_batting_stats, df1], ignore_index=True)\n",
    "            bar()\n",
    "    return df_batting_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a1e11",
   "metadata": {},
   "source": [
    "### Player bowling stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "315cd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_bowling_stats(df_players):\n",
    "    with alive_bar(len(df_players),force_tty=True) as bar:\n",
    "        df_bowling_stats = pd.DataFrame(columns=[\"Player_Name\",\"matches\",\"inns\",\"balls\",\"runs\",\"wkts\",\"BBI\",\n",
    "                                    \"bowling_ave\",\"Econ\",\"bowling_SR\",\"5W\",\"10W\"])\n",
    "        df_players=df_players\n",
    "        for ind in df_players.index:\n",
    "            url =\"https://www.espncricinfo.com/\"+df_players[\"Player_link\"][ind]\n",
    "            #print(url)\n",
    "            result = requests.get(url)\n",
    "            content = result.text\n",
    "            soup = BeautifulSoup(content, \"lxml\")\n",
    "\n",
    "            Player_Name = df_players[\"Player_name\"][ind]\n",
    "            box2= soup.find(\"p\",text=\"Bowling\")\n",
    "            #for row in box2.parent.tbody.find_all(\"tr\")[:3]:\n",
    "            for row in box2.parent.tbody.find_all(\"tr\"):\n",
    "                columns = row.find_all(\"td\")\n",
    "                if columns[0].span.get_text()==\"ODI\":    \n",
    "                    matches = columns[1].span.get_text()\n",
    "                    inns = columns[2].span.get_text()\n",
    "                    balls_bowled = columns[3].span.get_text()\n",
    "                    runs_against = columns[4].span.get_text()\n",
    "                    wkts = columns[5].span.get_text()\n",
    "                    BBI = columns[6].span.get_text()\n",
    "                    bowling_ave = columns[8].span.get_text()\n",
    "                    Econ = columns[9].span.get_text()\n",
    "                    bowling_SR = columns[10].span.get_text()\n",
    "                    wickets_5 = columns[12].span.get_text()\n",
    "                    wickets_10 = columns[13].span.get_text()\n",
    "\n",
    "                    #print(T20_matches,T20_BBI,T20_Econ,T20_Econ,T20_5W)\n",
    "            df1 =  pd.DataFrame([{\"Player_Name\":Player_Name,\n",
    "                                  \"matches\":matches,\n",
    "                                  \"inns\":inns,\n",
    "                                  \"balls_bowled\":balls_bowled,\n",
    "                                  \"runs_against\":runs_against,\n",
    "                                  \"wkts\":wkts,\n",
    "                                  \"BBI\":BBI,\n",
    "                                  \"bowling_ave\":bowling_ave,\n",
    "                                  \"Econ\":Econ,\n",
    "                                  \"bowling_SR\":bowling_SR,\n",
    "                                  \"5W\":wickets_5,\n",
    "                                  \"10W\":wickets_10\n",
    "                                  }])\n",
    "            #print(Name)\n",
    "            df_bowling_stats = pd.concat([df_bowling_stats, df1], ignore_index=True)\n",
    "            #print(ind)\n",
    "            bar()\n",
    "    return df_bowling_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d56bf",
   "metadata": {},
   "source": [
    "### Player Fielding Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9beff155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fielding_stats(df_players):\n",
    "    with alive_bar(len(df_players),force_tty=True) as bar:\n",
    "        df_fielding_stats = pd.DataFrame(columns = [\"Player_Name\",\"matches\",\"catches\",\"stumps\"])\n",
    "        \n",
    "        df_players=df_players\n",
    "        for ind in df_players.index:\n",
    "            url =\"https://www.espncricinfo.com/\"+df_players[\"Player_link\"][ind]\n",
    "            #print(url)\n",
    "            result = requests.get(url)\n",
    "            content = result.text\n",
    "            soup = BeautifulSoup(content, \"lxml\")\n",
    "\n",
    "            Player_Name = df_players[\"Player_name\"][ind]\n",
    "            box2= soup.find(\"p\",text=\"Batting & Fielding\")\n",
    "            for row in box2.parent.tbody.find_all(\"tr\"):\n",
    "                columns = row.find_all(\"td\")\n",
    "                if columns[0].span.get_text()==\"ODI\": \n",
    "                    matches = columns[1].span.get_text()\n",
    "                    catches = columns[13].span.get_text()\n",
    "                    stumps = columns[14].span.get_text()\n",
    "\n",
    "            df1 =  pd.DataFrame([{\"Player_Name\":Player_Name,\n",
    "                                  \"matches\":matches,\n",
    "                                  \"catches\":catches,\n",
    "                                  \"stumps\":stumps\n",
    "                                  }])\n",
    "            #print(Name)\n",
    "            df_fielding_stats = pd.concat([df_fielding_stats, df1], ignore_index=True)\n",
    "            bar()\n",
    "    return df_fielding_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f084db",
   "metadata": {},
   "source": [
    "### scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3019705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.espncricinfo.com/records/year/team-match-results/2018-2018/one-day-internationals-2?decade=201\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "|████████████████████████████████████████| 362/362 [100%] in 2:28.9 (2.42/s)    \n",
      "8\n",
      "|████████████████████████████████████████| 362/362 [100%] in 1:53.4 (3.19/s)    \n",
      "9\n",
      "|████████████████████████████████████████| 362/362 [100%] in 1:08.4 (5.30/s)    \n",
      "10\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2019-2019/one-day-internationals-2?decade=201\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "|████████████████████████████████████████| 402/402 [100%] in 2:57.1 (2.27/s)    \n",
      "8\n",
      "|████████████████████████████████████████| 402/402 [100%] in 2:28.3 (2.71/s)    \n",
      "9\n",
      "|████████████████████████████████████████| 402/402 [100%] in 3:22.6 (1.98/s)    \n",
      "10\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2020-2020/one-day-internationals-2?decade=202\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "|████████████████████████████████████████| 253/253 [100%] in 1:20.8 (3.12/s)    \n",
      "8\n",
      "|████████████████████████████████████████| 253/253 [100%] in 50.1s (5.05/s)     \n",
      "9\n",
      "|████████████████████████████████████████| 253/253 [100%] in 1:00.3 (4.18/s)    \n",
      "10\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2021-2021/one-day-internationals-2?decade=202\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "|████████████████████████████████████████| 361/361 [100%] in 1:25.0 (4.24/s)    \n",
      "8\n",
      "|████████████████████████████████████████| 361/361 [100%] in 2:34.9 (2.32/s)    \n",
      "9\n",
      "|████████████████████████████████████████| 361/361 [100%] in 1:25.5 (4.22/s)    \n",
      "10\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2022-2022/one-day-internationals-2?decade=202\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "|████████████████████████████████████████| 439/439 [100%] in 4:14.4 (1.72/s)    \n",
      "8\n",
      "|████████████████████████████████████████| 439/439 [100%] in 1:31.1 (4.82/s)    \n",
      "9\n",
      "|████████████████████████████████████████| 439/439 [100%] in 4:38.8 (1.57/s)    \n",
      "10\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2023-2023/one-day-internationals-2?decade=202\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "|████████████████████████████████████████| 400/400 [100%] in 2:18.9 (2.87/s)    \n",
      "8\n",
      "|████████████████████████████████████████| 400/400 [100%] in 2:45.3 (2.42/s)    \n",
      "9\n",
      "|████████████████████████████████████████| 400/400 [100%] in 3:28.3 (1.92/s)     ▆▄▂ 249/400 [62%] in 2:42 (~1:38, 1.5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "url_list=[\"https://www.espncricinfo.com/records/year/team-match-results/2018-2018/one-day-internationals-2?decade=201\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2019-2019/one-day-internationals-2?decade=201\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2020-2020/one-day-internationals-2?decade=202\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2021-2021/one-day-internationals-2?decade=202\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2022-2022/one-day-internationals-2?decade=202\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2023-2023/one-day-internationals-2?decade=202\"]\n",
    "\n",
    "for url in url_list:\n",
    "    \n",
    "    ######################################################################################\n",
    "    print(url)\n",
    "    \n",
    "    catch = re.search(r\"/(\\d{4}-\\d{4})/\", url)\n",
    "    if catch:\n",
    "        result = catch.group(1)\n",
    "        \n",
    "    season = result\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"match_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    match = scrape_match_dataset(url)\n",
    "    match[\"odi_year\"]=season\n",
    "    match.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"1\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"match_links_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    match_links = scrape_match_links(url)\n",
    "    match_links[\"odi_year\"]=season\n",
    "    match_links.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"2\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"batting_scorecard_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    batting_scorecard = scrape_batting_summary(match_links,match)\n",
    "    batting_scorecard[\"odi_year\"]=season\n",
    "    batting_scorecard.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"3\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"bowling_scorecard_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    bowling_scorecard = scrape_bowling_summary(match_links,match)\n",
    "    bowling_scorecard[\"odi_year\"]=season\n",
    "    bowling_scorecard.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"4\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"player_links_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    player_links = scrape_player_links(match_links)\n",
    "    player_links[\"odi_year\"]=season\n",
    "    player_links.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"5\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"player_details_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    player_details = scrape_player_details(player_links)\n",
    "    player_details[\"odi_year\"]=season\n",
    "    player_details.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"6\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"National_flag_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    National_flag = scrape_National_flag(match)\n",
    "    National_flag[\"odi_year\"]=season\n",
    "    National_flag.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "        \n",
    "    print(\"7\")    \n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"batting_stats_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    batting_stats = scrape_batting_stats(player_links)\n",
    "    batting_stats[\"odi_year\"]=season\n",
    "    batting_stats.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "        \n",
    "    print(\"8\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"bowling_stats_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    bowling_stats = scrape_bowling_stats(player_links)\n",
    "    bowling_stats[\"odi_year\"]=season\n",
    "    bowling_stats.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"9\")\n",
    "    ######################################################################################\n",
    "    \n",
    "    ######################################################################################\n",
    "    csv_filename = \"fielding_stats_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    fielding_stats = scrape_fielding_stats(player_links)\n",
    "    fielding_stats[\"odi_year\"]=season\n",
    "    fielding_stats.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)\n",
    "    \n",
    "    print(\"10\")\n",
    "    ######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b3a0d725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>matches</th>\n",
       "      <th>catches</th>\n",
       "      <th>stumps</th>\n",
       "      <th>WC_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Martin Guptill</td>\n",
       "      <td>198</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Brendon McCullum</td>\n",
       "      <td>260</td>\n",
       "      <td>262</td>\n",
       "      <td>15</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>161</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>236</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Grant Elliott</td>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>James Tredwell</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>Johnson Charles</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>Ehsan Adil</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>Tharindu Kaushal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2014to15-2014to15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       Player_Name  matches  catches  stumps            WC_year\n",
       "0             0    Martin Guptill      198      104       0  2014to15-2014to15\n",
       "1             1  Brendon McCullum      260      262      15  2014to15-2014to15\n",
       "2             2   Kane Williamson      161       64       0  2014to15-2014to15\n",
       "3             3       Ross Taylor      236      142       0  2014to15-2014to15\n",
       "4             4     Grant Elliott       83       17       0  2014to15-2014to15\n",
       "..          ...               ...      ...      ...     ...                ...\n",
       "200         200    James Tredwell       45       14       0  2014to15-2014to15\n",
       "201         201   Johnson Charles       58       25       2  2014to15-2014to15\n",
       "202         202        Ehsan Adil        6        0       0  2014to15-2014to15\n",
       "203         203  Tharindu Kaushal        1        0       0  2014to15-2014to15\n",
       "204         204        Matt Henry       72       23       0  2014to15-2014to15\n",
       "\n",
       "[205 rows x 6 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= pd.read_csv(\"fielding_stats_wc.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ac887ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49f6caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.espncricinfo.com/records/year/team-match-results/2018-2018/one-day-internationals-2?decade=201\n",
      "128\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2019-2019/one-day-internationals-2?decade=201\n",
      "150\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2020-2020/one-day-internationals-2?decade=202\n",
      "44\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2021-2021/one-day-internationals-2?decade=202\n",
      "71\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2022-2022/one-day-internationals-2?decade=202\n",
      "161\n",
      "https://www.espncricinfo.com/records/year/team-match-results/2023-2023/one-day-internationals-2?decade=202\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "url_list=[\"https://www.espncricinfo.com/records/year/team-match-results/2018-2018/one-day-internationals-2?decade=201\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2019-2019/one-day-internationals-2?decade=201\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2020-2020/one-day-internationals-2?decade=202\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2021-2021/one-day-internationals-2?decade=202\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2022-2022/one-day-internationals-2?decade=202\",\n",
    "         \"https://www.espncricinfo.com/records/year/team-match-results/2023-2023/one-day-internationals-2?decade=202\"]\n",
    "\n",
    "for url in url_list:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    csv_filename = \"match_data.csv\"\n",
    "    csv_exists = os.path.isfile(csv_filename)\n",
    "    # Create or append to the CSV file based on existence\n",
    "    mode = \"w\" if not csv_exists else \"a\"\n",
    "    \n",
    "    catch = re.search(r\"/(\\d{4}-\\d{4})/\", url)\n",
    "    if catch:\n",
    "        result = catch.group(1)\n",
    "        \n",
    "    season = result\n",
    "    \n",
    "    match = scrape_match_dataset(url)\n",
    "    print(len(match))\n",
    "    match[\"odi_year\"]=season\n",
    "    match.to_csv(csv_filename, mode=mode, index=False, header=not csv_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5833870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(\"match_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f76bf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1608"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cafb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
